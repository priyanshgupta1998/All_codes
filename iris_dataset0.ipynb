{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshgupta1998/All_codes/blob/master/iris_dataset0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YZz7X3pkOj2Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDyiM9OoOEjz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pntWabDmOEmz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3jeE8YLXOEql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "digits = datasets.load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wRj0l5UhOEtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        },
        "outputId": "16690f96-e4ff-437b-d66f-5b81ead364a4"
      },
      "cell_type": "code",
      "source": [
        "digits"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\",\n",
              " 'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "        ...,\n",
              "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
              " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
              "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
              "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
              "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
              "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
              "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
              "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
              "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
              "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
              " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
              " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "kDaOmRAwOEwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fdc0d653-269e-46c2-b368-7eb323fff8a4"
      },
      "cell_type": "code",
      "source": [
        "print(len(digits.data))\n",
        "print(digits.data) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1797\n",
            "[[ 0.  0.  5. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ... 10.  0.  0.]\n",
            " [ 0.  0.  0. ... 16.  9.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ...  6.  0.  0.]\n",
            " [ 0.  0.  2. ... 12.  0.  0.]\n",
            " [ 0.  0. 10. ... 12.  1.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kFH8pKz5PnGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "59ef38c0-41af-4983-9624-265b71671304"
      },
      "cell_type": "code",
      "source": [
        "digits.data[-1:]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0., 10., 14.,  8.,  1.,  0.,  0.,  0.,  2., 16., 14.,  6.,\n",
              "         1.,  0.,  0.,  0.,  0., 15., 15.,  8., 15.,  0.,  0.,  0.,  0.,\n",
              "         5., 16., 16., 10.,  0.,  0.,  0.,  0., 12., 15., 15., 12.,  0.,\n",
              "         0.,  0.,  4., 16.,  6.,  4., 16.,  6.,  0.,  0.,  8., 16., 10.,\n",
              "         8., 16.,  8.,  0.,  0.,  1.,  8., 12., 14., 12.,  1.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "1GRY-BYdO5si",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f4aac3c8-a509-435e-d49c-630000f85eb9"
      },
      "cell_type": "code",
      "source": [
        "print(len(digits.target))\n",
        "digits.target"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 8, 9, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "a2_LYA4kO5wE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c088b40d-8d3d-4cb0-ccb8-330792ca75fb"
      },
      "cell_type": "code",
      "source": [
        "digits.images[0]  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
              "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
              "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
              "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
              "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
              "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
              "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
              "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "_IF5sPL8O5yz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ed970085-4396-469e-9965-6d10e99f5404"
      },
      "cell_type": "code",
      "source": [
        "digits.images[1]  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.],\n",
              "       [ 0.,  0.,  0., 11., 16.,  9.,  0.,  0.],\n",
              "       [ 0.,  0.,  3., 15., 16.,  6.,  0.,  0.],\n",
              "       [ 0.,  7., 15., 16., 16.,  2.,  0.,  0.],\n",
              "       [ 0.,  0.,  1., 16., 16.,  3.,  0.,  0.],\n",
              "       [ 0.,  0.,  1., 16., 16.,  6.,  0.,  0.],\n",
              "       [ 0.,  0.,  1., 16., 16.,  6.,  0.,  0.],\n",
              "       [ 0.,  0.,  0., 11., 16., 10.,  0.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "xMVVVz7QO5_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d306ec41-e432-406c-b293-86968e57d96f"
      },
      "cell_type": "code",
      "source": [
        "digits.images[2]  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  0.,  4., 15., 12.,  0.,  0.],\n",
              "       [ 0.,  0.,  3., 16., 15., 14.,  0.,  0.],\n",
              "       [ 0.,  0.,  8., 13.,  8., 16.,  0.,  0.],\n",
              "       [ 0.,  0.,  1.,  6., 15., 11.,  0.,  0.],\n",
              "       [ 0.,  1.,  8., 13., 15.,  1.,  0.,  0.],\n",
              "       [ 0.,  9., 16., 16.,  5.,  0.,  0.,  0.],\n",
              "       [ 0.,  3., 13., 16., 16., 11.,  5.,  0.],\n",
              "       [ 0.,  0.,  0.,  3., 11., 16.,  9.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "eZNSulaLO58x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(gamma=0.001, C=100.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gSSlDHErO57N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "dfd93d7c-61ad-4382-c738-62f2b380b5cc"
      },
      "cell_type": "code",
      "source": [
        "clf.fit(digits.data[:-1], digits.target[:-1]) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
              "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "  tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "Fw68xPL1O54o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8f2798a-0c2b-4a0d-f114-0879da6e7c2e"
      },
      "cell_type": "code",
      "source": [
        "clf.predict(digits.data[-1:])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "N4IKeNBWO52L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6hr5UIQ4OEzx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UxUl3lXWQATL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5nSI7IdQAXU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G00BlHXuQAca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b06WoJuZQAfm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q9QJieP1QAjO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ea0ywfINQdW5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "94FzyaGIQAml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC  \n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3ZqKXN-QtbK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iris_data = pd.read_csv('/home/Iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6LPXdT5QtYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a249e070-7b9a-4ab1-c7b4-98ea1ec3b5bd"
      },
      "cell_type": "code",
      "source": [
        "iris_data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  sepal_length  sepal_width  petal_length  petal_width      species\n",
              "0   1           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1   2           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2   3           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3   4           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4   5           5.0          3.6           1.4          0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "Bs1Q_D93RoNI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (iris_data.feature_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0iItUxi1QtV6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = SVC(gamma='scale')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wL9Croy4RU1w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zg77-U2QtSo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.fit(iris.data, iris.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4ZtNZoGQISm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f0049af-7ea3-4924-854b-9ea4ccc6d0d8"
      },
      "cell_type": "code",
      "source": [
        "list(clf.predict(iris.data[:3]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "L7ZUIWluQIXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50803eba-5298-432e-a35b-5f8bdbabe97c"
      },
      "cell_type": "code",
      "source": [
        "clf.fit(iris.data, iris.target_names[iris.target])  \n",
        "list(clf.predict(iris.data[:3]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['setosa', 'setosa', 'setosa']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "PSMUkLshQIac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xoR6hdAEQIQT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "26bIrv4lZybV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4K15UWaxQAp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "82fbcb83-95ee-48a4-8be8-f6881ed02aba"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "datatrain = pd.read_csv('/home/Iris.csv')\n",
        "datatrain.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  sepal_length  sepal_width  petal_length  petal_width      species\n",
              "0   1           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1   2           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2   3           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3   4           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4   5           5.0          3.6           1.4          0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "rwX8LZH3UINq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1986
        },
        "outputId": "80148cb9-dd59-42e6-824b-a2e506566943"
      },
      "cell_type": "code",
      "source": [
        "datatrain.loc[datatrain['species']=='Iris-setosa', 'species']=0\n",
        "datatrain.loc[datatrain['species']=='Iris-versicolor', 'species']=1\n",
        "datatrain.loc[datatrain['species']=='Iris-virginica', 'species']=2\n",
        "\n",
        "datatrain = datatrain.apply(pd.to_numeric)\n",
        "\n",
        "print(len(datatrain))\n",
        "datatrain"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>5.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>5.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>5.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>5.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>121</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>122</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>123</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>124</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.7</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>125</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>126</td>\n",
              "      <td>7.2</td>\n",
              "      <td>3.2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>127</td>\n",
              "      <td>6.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>128</td>\n",
              "      <td>6.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>129</td>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>130</td>\n",
              "      <td>7.2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>131</td>\n",
              "      <td>7.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>132</td>\n",
              "      <td>7.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>6.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>133</td>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>134</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>135</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>5.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>136</td>\n",
              "      <td>7.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>137</td>\n",
              "      <td>6.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>138</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.5</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>139</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>140</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>141</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>142</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>143</td>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>144</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5.9</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>145</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  sepal_length  sepal_width  petal_length  petal_width  species\n",
              "0      1           5.1          3.5           1.4          0.2        0\n",
              "1      2           4.9          3.0           1.4          0.2        0\n",
              "2      3           4.7          3.2           1.3          0.2        0\n",
              "3      4           4.6          3.1           1.5          0.2        0\n",
              "4      5           5.0          3.6           1.4          0.2        0\n",
              "5      6           5.4          3.9           1.7          0.4        0\n",
              "6      7           4.6          3.4           1.4          0.3        0\n",
              "7      8           5.0          3.4           1.5          0.2        0\n",
              "8      9           4.4          2.9           1.4          0.2        0\n",
              "9     10           4.9          3.1           1.5          0.1        0\n",
              "10    11           5.4          3.7           1.5          0.2        0\n",
              "11    12           4.8          3.4           1.6          0.2        0\n",
              "12    13           4.8          3.0           1.4          0.1        0\n",
              "13    14           4.3          3.0           1.1          0.1        0\n",
              "14    15           5.8          4.0           1.2          0.2        0\n",
              "15    16           5.7          4.4           1.5          0.4        0\n",
              "16    17           5.4          3.9           1.3          0.4        0\n",
              "17    18           5.1          3.5           1.4          0.3        0\n",
              "18    19           5.7          3.8           1.7          0.3        0\n",
              "19    20           5.1          3.8           1.5          0.3        0\n",
              "20    21           5.4          3.4           1.7          0.2        0\n",
              "21    22           5.1          3.7           1.5          0.4        0\n",
              "22    23           4.6          3.6           1.0          0.2        0\n",
              "23    24           5.1          3.3           1.7          0.5        0\n",
              "24    25           4.8          3.4           1.9          0.2        0\n",
              "25    26           5.0          3.0           1.6          0.2        0\n",
              "26    27           5.0          3.4           1.6          0.4        0\n",
              "27    28           5.2          3.5           1.5          0.2        0\n",
              "28    29           5.2          3.4           1.4          0.2        0\n",
              "29    30           4.7          3.2           1.6          0.2        0\n",
              "..   ...           ...          ...           ...          ...      ...\n",
              "120  121           6.9          3.2           5.7          2.3        2\n",
              "121  122           5.6          2.8           4.9          2.0        2\n",
              "122  123           7.7          2.8           6.7          2.0        2\n",
              "123  124           6.3          2.7           4.9          1.8        2\n",
              "124  125           6.7          3.3           5.7          2.1        2\n",
              "125  126           7.2          3.2           6.0          1.8        2\n",
              "126  127           6.2          2.8           4.8          1.8        2\n",
              "127  128           6.1          3.0           4.9          1.8        2\n",
              "128  129           6.4          2.8           5.6          2.1        2\n",
              "129  130           7.2          3.0           5.8          1.6        2\n",
              "130  131           7.4          2.8           6.1          1.9        2\n",
              "131  132           7.9          3.8           6.4          2.0        2\n",
              "132  133           6.4          2.8           5.6          2.2        2\n",
              "133  134           6.3          2.8           5.1          1.5        2\n",
              "134  135           6.1          2.6           5.6          1.4        2\n",
              "135  136           7.7          3.0           6.1          2.3        2\n",
              "136  137           6.3          3.4           5.6          2.4        2\n",
              "137  138           6.4          3.1           5.5          1.8        2\n",
              "138  139           6.0          3.0           4.8          1.8        2\n",
              "139  140           6.9          3.1           5.4          2.1        2\n",
              "140  141           6.7          3.1           5.6          2.4        2\n",
              "141  142           6.9          3.1           5.1          2.3        2\n",
              "142  143           5.8          2.7           5.1          1.9        2\n",
              "143  144           6.8          3.2           5.9          2.3        2\n",
              "144  145           6.7          3.3           5.7          2.5        2\n",
              "145  146           6.7          3.0           5.2          2.3        2\n",
              "146  147           6.3          2.5           5.0          1.9        2\n",
              "147  148           6.5          3.0           5.2          2.0        2\n",
              "148  149           6.2          3.4           5.4          2.3        2\n",
              "149  150           5.9          3.0           5.1          1.8        2\n",
              "\n",
              "[150 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "KQXwycFYUehD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datatrain_array = datatrain.as_matrix()\n",
        "datatrain_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q9dyI7f6Uw7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "54afed5f-292e-4c33-f5e1-27d546eeac7f"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(datatrain_array[:,:4],\n",
        "                                                    datatrain_array[:,4],\n",
        "                                                    test_size=0.2)\n",
        "print(X_train[:5])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 87.    6.7   3.1   4.7]\n",
            " [ 53.    6.9   3.1   4.9]\n",
            " [ 62.    5.9   3.    4.2]\n",
            " [ 95.    5.6   2.7   4.2]\n",
            " [149.    6.2   3.4   5.4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ubdHNROlU77_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5497edf4-adc8-4862-b5c4-88ee71ed8a8c"
      },
      "cell_type": "code",
      "source": [
        "print(X_test[:5])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[120.    6.    2.2   5. ]\n",
            " [  6.    5.4   3.9   1.7]\n",
            " [140.    6.9   3.1   5.4]\n",
            " [119.    7.7   2.6   6.9]\n",
            " [ 33.    5.2   4.1   1.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PL0CNccUUIJg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10),solver='sgd',learning_rate_init=0.01,max_iter=500)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uDuKM1T8VlSH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cf4c2c0d-de58-471a-9f5f-4edf9420c3ac"
      },
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.5, 1.5, 1.5, 1.3, 2.3, 0.2, 0.2, 1.4, 0.3, 1.3, 1.3, 0.4, 0.2,\n",
              "       0.3, 1.6, 0.6, 0.2, 1. , 1.8, 0.3, 2.3, 1.8, 0.2, 0.4, 0.2, 1.5,\n",
              "       1.9, 1.1, 0.4, 2.2, 0.2, 2.4, 1.9, 0.4, 1. , 2.4, 2.1, 2.1, 1.4,\n",
              "       1.8, 0.3, 1.2, 1.5, 1. , 0.1, 1. , 2.3, 0.2, 1.4, 0.2, 2.2, 1.8,\n",
              "       1. , 0.2, 1.9, 1.1, 2.1, 1.4, 0.2, 1.4, 0.2, 0.3, 1.3, 1.3, 1.8,\n",
              "       1.3, 1.5, 0.2, 1.3, 2. , 1.3, 2. , 1.8, 1.2, 0.2, 0.1, 1.8, 2. ,\n",
              "       0.1, 0.2, 1.5, 2. , 2. , 1.3, 1.6, 0.2, 2.3, 1.7, 2.1, 1.5, 2.3,\n",
              "       1. , 0.2, 0.3, 1.3, 1.4, 1.8, 1.2, 1.6, 1.4, 0.2, 2.5, 0.1, 0.2,\n",
              "       0.4, 2.1, 0.2, 1.2, 1. , 1.3, 1.2, 0.2, 0.2, 1.8, 0.2, 0.2, 1.9,\n",
              "       1.5, 2. , 1.3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "NQpn4Vh9VniH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9a456fc4-c735-46d8-99cc-536048c5d6bc"
      },
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.5, 0.4, 2.1, 2.3, 0.1, 0.5, 1.9, 0.1, 1.5, 0.2, 0.4, 0.2, 1.8,\n",
              "       1.1, 1.3, 0.3, 2.2, 2.3, 1.8, 2.4, 1.4, 0.2, 1.7, 1.8, 2.5, 2.3,\n",
              "       2.5, 1.6, 1.5, 0.2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "ehYDobmLXjJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "58784477-f790-4930-e017-c86db940b7f0"
      },
      "cell_type": "code",
      "source": [
        "y_train = y_train.astype('int')\n",
        "y_train"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 2, 1,\n",
              "       0, 0, 0, 1, 1, 1, 0, 2, 0, 2, 1, 0, 1, 2, 2, 2, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 2, 0, 1, 0, 2, 1, 1, 0, 1, 1, 2, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 2, 1, 2, 1, 1, 0, 0, 1, 2, 0, 0, 1, 2, 2, 1, 1, 0, 2, 1,\n",
              "       2, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 1, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "do0SRDxeQAto",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5d29a90a-7bcb-409e-9c1b-886679f3f55b"
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "mlp.fit(X_train, y_train)\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=10, learning_rate='constant',\n",
              "       learning_rate_init=0.01, max_iter=500, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2d6Vw08Vjsn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e101ac37-ab6e-4613-cebf-96127a445498"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Test the model\n",
        "print( mlp.score(X_test,y_test.astype('int')))\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0f6Zg0LqT1Xb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sl = 5.8\n",
        "sw = 4.0\n",
        "pl = 1.2\n",
        "pw = 0.2\n",
        "data = [[sl,sw,pl,pw]]\n",
        "# data = data.reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Pl-dx-VT1c6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71475a0f-10d8-4c5a-8a70-0e3f0031302d"
      },
      "cell_type": "code",
      "source": [
        "print(mlp.predict(X_test))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2P69umhxT1am",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9146dc89-2303-4694-9930-c4345a5d165c"
      },
      "cell_type": "code",
      "source": [
        "y_test.astype('int')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 2, 2, 1, 2, 1, 0,\n",
              "       1, 1, 2, 2, 2, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "metadata": {
        "id": "y0mIH1r-cF0K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pu0j1EqfeCqQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Final"
      ]
    },
    {
      "metadata": {
        "id": "qzg74LB7cFVu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crAhqbjlcFTZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loading dataset\n",
        "iris_dataset = datasets.load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhTc-IdLcI4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97e88927-193d-4c4e-cf9a-d2aa7a44a694"
      },
      "cell_type": "code",
      "source": [
        "#The dataset is stored as a dict, we are inspecting datset with this\n",
        "iris_dataset.keys()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {
        "id": "bhRCozhdcJA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = iris_dataset['data']\n",
        "classes = iris_dataset['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IFO5JnoqcJEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a5036e32-372e-4524-8d72-9fda921d2bf1"
      },
      "cell_type": "code",
      "source": [
        "print(data[:10])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Sy5DHFpcJPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3017435a-8b02-4f36-d673-e73266abcaa7"
      },
      "cell_type": "code",
      "source": [
        "print(classes[:10])\n",
        "print(np.unique(classes), \"<-- Classes in our dataset\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0]\n",
            "[0 1 2] <-- Classes in our dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKHXiLIscJNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1344579a-1b0e-4ee0-84c3-a869090a25d4"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print('In this dataset we have: {} classes.'.format(np.max(classes) + 1))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In this dataset we have: 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m6xFA_I6cJLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c818c53-6626-425b-b8b0-1c4376b0caa6"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(iris_dataset['feature_names'])"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tkibiOGZcJJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8c34e66f-0b1a-4157-94c4-e8ae9d575ce8"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "plt.scatter(data[:, 2], data[:, 3])\n",
        "plt.scatter(data[:, 0], data[:, 1])\n",
        "plt.show()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD4CAYAAAAuNhccAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UtWlRAPycJHd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UVIVwsgqcI-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1N9gavdHcI8E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c7yf0hPZcI2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(scaled_data, classes, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgqfbfYUcI0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "db2d1a20-4be1-45e1-c642-7ad9eb58a378"
      },
      "cell_type": "code",
      "source": [
        "print(\"X_train has shape: {}\".format(X_train.shape))\n",
        "print(\"X_test has shape: {}\".format(X_test.shape))\n",
        "print(\"y_train has shape: {}\".format(y_train.shape))\n",
        "print(\"y_test has shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train has shape: (105, 4)\n",
            "X_test has shape: (45, 4)\n",
            "y_train has shape: (105,)\n",
            "y_test has shape: (45,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oBNtI_vwcFRa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cSLDUheXcFPA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifer = LogisticRegression(C=1.0, max_iter=1000, solver='newton-cg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bLZlBy7PcFM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "046ae4f4-ca0c-4dab-83cd-af99f86b79a7"
      },
      "cell_type": "code",
      "source": [
        "classifer.fit(X_train, y_train)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "metadata": {
        "id": "lXgcy4stcFKe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = classifer.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l08PL1bzdn7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6a4fa439-a791-40ab-8669-873faf74db0a"
      },
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1,\n",
              "       2, 1, 1, 1, 1, 0, 0, 0, 1, 2, 2, 0, 2, 0, 1, 2, 1, 1, 1, 1, 2, 2,\n",
              "       0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "metadata": {
        "id": "_XjlK_92dyhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c9a6f416-ba69-4a3b-eca9-d1bcc10d9177"
      },
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 1, 0, 0, 1, 2, 2, 2, 1,\n",
              "       2, 1, 1, 1, 2, 0, 0, 0, 1, 2, 2, 0, 2, 0, 1, 2, 1, 1, 2, 1, 2, 2,\n",
              "       0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "metadata": {
        "id": "y3ceLA5mcFIE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mzDGLc8IcFF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5730cc1-cd50-49b3-a022-1ddace49b953"
      },
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_test, pred))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cbIgX2vVcFDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from sklearn.grid_search import GridSearchCV     -----> it has been updated \n",
        "from sklearn.model_selection import learning_curve, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J5NhN7v_egjo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param_grid = {'C':[10, 100, 1000], 'max_iter':[100, 1000, 10000]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urzhNPrGegfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(classifer, param_grid=param_grid, verbose=10, cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJVFngDQegdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3522
        },
        "outputId": "66353b75-c6f6-4c39-8e6e-47e11d47cf8b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] C=10, max_iter=100 ..............................................\n",
            "[CV] ..... C=10, max_iter=100, score=0.9565217391304348, total=   0.0s\n",
            "[CV] C=10, max_iter=100 ..............................................\n",
            "[CV] .................... C=10, max_iter=100, score=1.0, total=   0.0s\n",
            "[CV] C=10, max_iter=100 ..............................................\n",
            "[CV] .................... C=10, max_iter=100, score=1.0, total=   0.0s\n",
            "[CV] C=10, max_iter=100 ..............................................\n",
            "[CV] .................... C=10, max_iter=100, score=0.9, total=   0.0s\n",
            "[CV] C=10, max_iter=100 ..............................................\n",
            "[CV] .................... C=10, max_iter=100, score=1.0, total=   0.0s\n",
            "[CV] C=10, max_iter=1000 .............................................\n",
            "[CV] .... C=10, max_iter=1000, score=0.9565217391304348, total=   0.0s\n",
            "[CV] C=10, max_iter=1000 .............................................\n",
            "[CV] ................... C=10, max_iter=1000, score=1.0, total=   0.0s\n",
            "[CV] C=10, max_iter=1000 .............................................\n",
            "[CV] ................... C=10, max_iter=1000, score=1.0, total=   0.0s\n",
            "[CV] C=10, max_iter=1000 .............................................\n",
            "[CV] ................... C=10, max_iter=1000, score=0.9, total=   0.0s\n",
            "[CV] C=10, max_iter=1000 .............................................\n",
            "[CV] ................... C=10, max_iter=1000, score=1.0, total=   0.0s\n",
            "[CV] C=10, max_iter=10000 ............................................\n",
            "[CV] ... C=10, max_iter=10000, score=0.9565217391304348, total=   0.0s\n",
            "[CV] C=10, max_iter=10000 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................. C=10, max_iter=10000, score=1.0, total=   0.0s\n",
            "[CV] C=10, max_iter=10000 ............................................\n",
            "[CV] .................. C=10, max_iter=10000, score=1.0, total=   0.0s\n",
            "[CV] C=10, max_iter=10000 ............................................\n",
            "[CV] .................. C=10, max_iter=10000, score=0.9, total=   0.0s\n",
            "[CV] C=10, max_iter=10000 ............................................\n",
            "[CV] .................. C=10, max_iter=10000, score=1.0, total=   0.0s\n",
            "[CV] C=100, max_iter=100 .............................................\n",
            "[CV] .... C=100, max_iter=100, score=0.9565217391304348, total=   0.0s\n",
            "[CV] C=100, max_iter=100 .............................................\n",
            "[CV] ................... C=100, max_iter=100, score=1.0, total=   0.0s\n",
            "[CV] C=100, max_iter=100 .............................................\n",
            "[CV] ................... C=100, max_iter=100, score=1.0, total=   0.0s\n",
            "[CV] C=100, max_iter=100 .............................................\n",
            "[CV] .................. C=100, max_iter=100, score=0.95, total=   0.0s\n",
            "[CV] C=100, max_iter=100 .............................................\n",
            "[CV] ................... C=100, max_iter=100, score=1.0, total=   0.0s\n",
            "[CV] C=100, max_iter=1000 ............................................\n",
            "[CV] ... C=100, max_iter=1000, score=0.9565217391304348, total=   0.0s\n",
            "[CV] C=100, max_iter=1000 ............................................\n",
            "[CV] .................. C=100, max_iter=1000, score=1.0, total=   0.0s\n",
            "[CV] C=100, max_iter=1000 ............................................\n",
            "[CV] .................. C=100, max_iter=1000, score=1.0, total=   0.0s\n",
            "[CV] C=100, max_iter=1000 ............................................\n",
            "[CV] ................. C=100, max_iter=1000, score=0.95, total=   0.0s\n",
            "[CV] C=100, max_iter=1000 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................. C=100, max_iter=1000, score=1.0, total=   0.0s\n",
            "[CV] C=100, max_iter=10000 ...........................................\n",
            "[CV] .. C=100, max_iter=10000, score=0.9565217391304348, total=   0.0s\n",
            "[CV] C=100, max_iter=10000 ...........................................\n",
            "[CV] ................. C=100, max_iter=10000, score=1.0, total=   0.0s\n",
            "[CV] C=100, max_iter=10000 ...........................................\n",
            "[CV] ................. C=100, max_iter=10000, score=1.0, total=   0.0s\n",
            "[CV] C=100, max_iter=10000 ...........................................\n",
            "[CV] ................ C=100, max_iter=10000, score=0.95, total=   0.0s\n",
            "[CV] C=100, max_iter=10000 ...........................................\n",
            "[CV] ................. C=100, max_iter=10000, score=1.0, total=   0.0s\n",
            "[CV] C=1000, max_iter=100 ............................................\n",
            "[CV] ... C=1000, max_iter=100, score=0.9565217391304348, total=   0.0s\n",
            "[CV] C=1000, max_iter=100 ............................................\n",
            "[CV] .................. C=1000, max_iter=100, score=1.0, total=   0.0s\n",
            "[CV] C=1000, max_iter=100 ............................................\n",
            "[CV] .................. C=1000, max_iter=100, score=1.0, total=   0.0s\n",
            "[CV] C=1000, max_iter=100 ............................................\n",
            "[CV] ................. C=1000, max_iter=100, score=0.95, total=   0.0s\n",
            "[CV] C=1000, max_iter=100 ............................................\n",
            "[CV] .................. C=1000, max_iter=100, score=1.0, total=   0.0s\n",
            "[CV] C=1000, max_iter=1000 ...........................................\n",
            "[CV] .. C=1000, max_iter=1000, score=0.9565217391304348, total=   0.0s\n",
            "[CV] C=1000, max_iter=1000 ...........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................. C=1000, max_iter=1000, score=1.0, total=   0.0s\n",
            "[CV] C=1000, max_iter=1000 ...........................................\n",
            "[CV] ................. C=1000, max_iter=1000, score=1.0, total=   0.0s\n",
            "[CV] C=1000, max_iter=1000 ...........................................\n",
            "[CV] ................ C=1000, max_iter=1000, score=0.95, total=   0.0s\n",
            "[CV] C=1000, max_iter=1000 ...........................................\n",
            "[CV] ................. C=1000, max_iter=1000, score=1.0, total=   0.0s\n",
            "[CV] C=1000, max_iter=10000 ..........................................\n",
            "[CV] . C=1000, max_iter=10000, score=0.9565217391304348, total=   0.0s\n",
            "[CV] C=1000, max_iter=10000 ..........................................\n",
            "[CV] ................ C=1000, max_iter=10000, score=1.0, total=   0.0s\n",
            "[CV] C=1000, max_iter=10000 ..........................................\n",
            "[CV] ................ C=1000, max_iter=10000, score=1.0, total=   0.0s\n",
            "[CV] C=1000, max_iter=10000 ..........................................\n",
            "[CV] ............... C=1000, max_iter=10000, score=0.95, total=   0.0s\n",
            "[CV] C=1000, max_iter=10000 ..........................................\n",
            "[CV] ................ C=1000, max_iter=10000, score=1.0, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    0.8s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
              "          tol=0.0001, verbose=0, warm_start=False),\n",
              "       fit_params=None, iid='warn', n_jobs=None,\n",
              "       param_grid={'C': [10, 100, 1000], 'max_iter': [100, 1000, 10000]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "1NRFjAbtegZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9787b148-6709-4873-8c07-a993a087d1e6"
      },
      "cell_type": "code",
      "source": [
        "print(grid.best_estimator_)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pfC_XnTMegWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifer = LogisticRegression(C=1000.0, max_iter=100, solver='newton-cg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-bQBzZregSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ffc57575-d621-458f-fd4a-32dfcbd33fdb"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "classifer.fit(X_train, y_train)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
              "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
              "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
              "          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "metadata": {
        "id": "KjuXNxXEegOT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = classifer.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l0xoFOqveGCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b80a216-2787-4ec9-d8ca-020f79785d68"
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy on test after change: {}%\".format(accuracy_score(y_test, pred)*100))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test after change: 93.33333333333333%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xVz3zEOVeGHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B0YDIEi3eGVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xSlFv6MeeGTR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WYapS41seGQa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GNvZiHY3eGOZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J7bqopo3eGMB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5D8ljmNNcFA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}